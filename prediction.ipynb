{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21 midi2audio\n",
    "!apt-get update\n",
    "!apt-get install -y fluidsynth musescore3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from music21 import stream,note,chord,duration\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lookups.pkl\",\"rb\") as f:\n",
    "    lookups = pickle.load(f)\n",
    "note_to_int = lookups[\"n2i\"]\n",
    "int_to_note = lookups[\"i2n\"]\n",
    "duration_to_int = lookups[\"d2i\"]\n",
    "int_to_duration = lookups[\"i2d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url:str, filename:str)->pathlib.Path:\n",
    "    import functools\n",
    "    import shutil\n",
    "    import requests\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    if r.status_code != 200:\n",
    "        r.raise_for_status()  # Will only raise for 4xx codes, so...\n",
    "        raise RuntimeError(f\"Request to {url} returned status code {r.status_code}\\n Please download the captioner.pt file manually from the link provided in the README.md file.\") \n",
    "    file_size = int(r.headers.get('Content-Length', 0))\n",
    "\n",
    "    path = pathlib.Path(filename).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "    r.raw.read = functools.partial(r.raw.read, decode_content=True)  # Decompress if needed\n",
    "    with tqdm.wrapattr(r.raw, \"read\", total=file_size, desc=desc) as r_raw:\n",
    "        with path.open(\"wb\") as f:\n",
    "            shutil.copyfileobj(r_raw, f)\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicModel(nn.Module):\n",
    "    def __init__(self, n_notes,n_durations,embed_size = 128,rnn_units = 512):\n",
    "        super(MusicModel, self).__init__()\n",
    "\n",
    "        self.rnn_units = rnn_units\n",
    "        self.ne = nn.Embedding(n_notes,embed_size)\n",
    "        self.de = nn.Embedding(n_durations,embed_size)\n",
    "        self.concat = lambda x1,x2: torch.cat([x1,x2],axis =-1)\n",
    "        self.lstm1 = nn.GRU(2*embed_size,self.rnn_units,batch_first = True)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        self.lstm2 = nn.GRU(self.rnn_units,self.rnn_units,num_layers = 2,batch_first = True)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(self.rnn_units,self.rnn_units*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.rnn_units*8,self.rnn_units*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.rnn_units*4,self.rnn_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.out1 = nn.Linear(self.rnn_units,n_notes)\n",
    "        self.out2 = nn.Linear(self.rnn_units,n_durations)\n",
    "        self.example_input_array = [torch.randint(0,10,(2,32))]*2\n",
    "\n",
    "\n",
    "    def forward(self,xn,xd):\n",
    "        xn = self.ne(xn)\n",
    "        xd = self.de(xd)\n",
    "        x = self.concat(xn,xd)\n",
    "        x,_ = self.lstm1(x)\n",
    "        x = self.drop1(x)\n",
    "        x,_ = self.lstm2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.seq(x[:,-1])\n",
    "        return self.out1(x),self.out2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicModel(\n",
       "  (ne): Embedding(3373, 128)\n",
       "  (de): Embedding(41, 128)\n",
       "  (lstm1): GRU(256, 512, batch_first=True)\n",
       "  (drop1): Dropout(p=0.3, inplace=False)\n",
       "  (lstm2): GRU(512, 512, num_layers=2, batch_first=True)\n",
       "  (drop2): Dropout(p=0.3, inplace=False)\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (out1): Linear(in_features=512, out_features=3373, bias=True)\n",
       "  (out2): Linear(in_features=512, out_features=41, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    save = torch.load(r\"MusicGenModel.ckpt\",map_location = device)\n",
    "except:\n",
    "    print(\"Model not found. Downloading model\")\n",
    "    url = \"https://drive.usercontent.google.com/download?id=1uzNchPVinjD4GwRm8EDzhEGHLxlOBQmf&export=download&authuser=0&confirm=t&uuid=37e737d6-5127-481a-a7a5-c50e79ca0296&at=APZUnTWUM6C5P-G22X6PXowUcXNF%3A1723283287938\"\n",
    "    path = download(url, \"MusicGenModel.ckpt\")\n",
    "    save = torch.load(path,map_location = device)\n",
    "\n",
    "model = MusicModel(**save[\"hyper_parameters\"])\n",
    "model.load_state_dict(save[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def generator(note_count = 100):\n",
    "\n",
    "    note_seed = np.array([note_to_int['START'] for _ in range(32)])\n",
    "    dur_seed = np.array([duration_to_int[0] for _ in range(32)])\n",
    "\n",
    "    notes_pred = []\n",
    "    dur_preds = []\n",
    "    for i in tqdm(range(note_count)):\n",
    "        note_seed = note_seed.reshape(1,32)\n",
    "        dur_seed = dur_seed.reshape(1,32)\n",
    "        pred = model(torch.tensor(note_seed,device = device),torch.tensor(dur_seed,device = device))\n",
    "\n",
    "        if i<note_count//5:\n",
    "            #probabilistic choice\n",
    "            notes_probs = F.softmax(pred[0],dim = 1)\n",
    "            dur_probs = F.softmax(pred[1],dim = 1)\n",
    "\n",
    "            note = torch.multinomial(notes_probs,num_samples = 1).item()\n",
    "            dur = torch.multinomial(dur_probs,num_samples = 1).item()\n",
    "        else:\n",
    "            #deterministic choice:\n",
    "            note = pred[0].argmax().item()\n",
    "            dur = pred[1].argmax().item()\n",
    "\n",
    "        notes_pred.append(int_to_note[note])\n",
    "        dur_preds.append(int_to_duration[dur])\n",
    "\n",
    "        note_seed = np.insert(note_seed[0],len(note_seed[0]),note)[1:]\n",
    "        dur_seed = np.insert(dur_seed[0],len(dur_seed[0]),dur)[1:]\n",
    "\n",
    "    return notes_pred,dur_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(out_notes,out_durs):\n",
    "    s = stream.Stream()\n",
    "    # Iterate over the notes and durations\n",
    "    for note_str, dur in zip(out_notes, out_durs):\n",
    "        if dur == 0 or note_str == 'START':  # If duration is zero, it's a rest\n",
    "            m21_note = note.Rest()\n",
    "        elif '.' in note_str:  # It's a chord\n",
    "            chord_notes = [note.Note(n) for n in note_str.split('.')]\n",
    "            m21_note = chord.Chord(chord_notes)\n",
    "        else:  # It's a single note\n",
    "            m21_note = note.Note(note_str)\n",
    "\n",
    "        m21_note.duration = duration.Duration(dur)\n",
    "        s.append(m21_note)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FluidSynth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867ac4cb1b6b49c89ceb190a265d5cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody contains rest notes. Unable to call mel.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mel.mid'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = convert(*generator(100))\n",
    "try:\n",
    "    mel.show()\n",
    "except:\n",
    "    print(\"Melody contains rest notes. Unable to call mel.show()\")\n",
    "\n",
    "mel.write(\"midi\",\"mel.mid\")\n",
    "fs.midi_to_audio(\"mel.mid\",\"melody.wav\")\n",
    "os.remove(\"mel.mid\")\n",
    "\n",
    "display(Audio(\"melody.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
